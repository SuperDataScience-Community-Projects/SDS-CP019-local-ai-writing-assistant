{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efec3f6-d3d9-404c-b96b-1dd396820fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa968aa7-4f73-4d3c-9fb1-802194fcc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from IPython.display import Markdown\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebd5610-5d27-4bb6-a4af-d9a48ceb8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= \"llama2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13052563-b41f-412c-b9a1-3c00236ce731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdddb278-3a56-43d4-8c07-a8e0bc8dbdc1",
   "metadata": {},
   "source": [
    "## Testing ollama Text Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae57708-0566-4879-8f74-3419c05f4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Generate a short story not more than 250 words about titanic with a title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df774ac8-1cf7-4aeb-8335-b802c06dbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ollama.generate(model=model,\n",
    "                        prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c750191d-bc77-4a79-b7eb-8ad199b97520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: The Tragic Fate of the Titanic\n",
      "\n",
      "It was the year 1912, and the RMS Titanic was considered the most luxurious and technologically advanced ship in the world. On its maiden voyage from Southampton to New York, the Titanic set sail with over 2,000 passengers and crew on board. But little did they know, their fate was already sealed.\n",
      "\n",
      "As the ship steamed through the night, a lookout spotted an iceberg in the distance. Despite the warnings from the lookout, the Titanic hit the massive iceberg with a deafening crash. The impact caused the ship to take on water, and it quickly became clear that the Titanic was doomed.\n",
      "\n",
      "Panic set in as passengers rushed to lifeboats, but not enough space existed for everyone on board. Hundreds of people were left stranded on the sinking ship, including many children and women. The night was filled with cries and screams as the Titanic slowly sank into the freezing waters of the North Atlantic.\n",
      "\n",
      "In the end, only a few hundred survivors were rescued by the RMS Carpathia, which arrived on the scene several hours later. The Titanic disaster was one of the deadliest maritime accidents in history, and it would forever change the way ships were designed and operated. Despite the tragedy, the legend of the Titanic lived on, a reminder of the power of nature and the frailty of human endeavor.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ccef8b3-5388-4de2-aea6-99115f2d36e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ollama._types.GenerateResponse"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e99d1a24-3aa0-4d8c-9cf7-37019735dc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateResponse(model='llama2', created_at='2025-01-04T15:41:22.399634Z', done=True, done_reason='stop', total_duration=40848444250, load_duration=633568542, prompt_eval_count=40, prompt_eval_duration=8484000000, eval_count=344, eval_duration=31665000000, response='\\nTitle: The Tragic Fate of the Titanic\\n\\nIt was the year 1912, and the RMS Titanic was considered the most luxurious and technologically advanced ship in the world. On its maiden voyage from Southampton to New York, the Titanic set sail with over 2,000 passengers and crew on board. But little did they know, their fate was already sealed.\\n\\nAs the ship steamed through the night, a lookout spotted an iceberg in the distance. Despite the warnings from the lookout, the Titanic hit the massive iceberg with a deafening crash. The impact caused the ship to take on water, and it quickly became clear that the Titanic was doomed.\\n\\nPanic set in as passengers rushed to lifeboats, but not enough space existed for everyone on board. Hundreds of people were left stranded on the sinking ship, including many children and women. The night was filled with cries and screams as the Titanic slowly sank into the freezing waters of the North Atlantic.\\n\\nIn the end, only a few hundred survivors were rescued by the RMS Carpathia, which arrived on the scene several hours later. The Titanic disaster was one of the deadliest maritime accidents in history, and it would forever change the way ships were designed and operated. Despite the tragedy, the legend of the Titanic lived on, a reminder of the power of nature and the frailty of human endeavor.', context=[518, 25580, 29962, 3532, 14816, 29903, 29958, 5299, 829, 14816, 29903, 6778, 13, 13, 5631, 403, 263, 3273, 5828, 451, 901, 1135, 29871, 29906, 29945, 29900, 3838, 1048, 4329, 273, 293, 411, 263, 3611, 518, 29914, 25580, 29962, 13, 13, 7030, 29901, 450, 323, 1431, 293, 383, 403, 310, 278, 323, 8929, 293, 13, 13, 3112, 471, 278, 1629, 29871, 29896, 29929, 29896, 29906, 29892, 322, 278, 390, 4345, 323, 8929, 293, 471, 5545, 278, 1556, 21684, 332, 2738, 322, 5722, 1189, 1711, 12862, 7751, 297, 278, 3186, 29889, 1551, 967, 611, 3615, 17775, 515, 4275, 314, 12533, 304, 1570, 3088, 29892, 278, 323, 8929, 293, 731, 14892, 411, 975, 29871, 29906, 29892, 29900, 29900, 29900, 28134, 322, 17616, 373, 7613, 29889, 1205, 2217, 1258, 896, 1073, 29892, 1009, 23779, 471, 2307, 409, 7943, 29889, 13, 13, 2887, 278, 7751, 1886, 2795, 1549, 278, 4646, 29892, 263, 1106, 449, 805, 15048, 385, 14890, 2552, 297, 278, 5418, 29889, 19454, 278, 18116, 515, 278, 1106, 449, 29892, 278, 323, 8929, 293, 7124, 278, 20364, 14890, 2552, 411, 263, 316, 2142, 8333, 8095, 29889, 450, 10879, 8581, 278, 7751, 304, 2125, 373, 4094, 29892, 322, 372, 9098, 3897, 2821, 393, 278, 323, 8929, 293, 471, 437, 27067, 29889, 13, 13, 23684, 293, 731, 297, 408, 28134, 364, 15392, 304, 11747, 774, 29877, 1446, 29892, 541, 451, 3307, 2913, 22856, 363, 14332, 373, 7613, 29889, 379, 6453, 29879, 310, 2305, 892, 2175, 851, 392, 287, 373, 278, 269, 18159, 7751, 29892, 3704, 1784, 4344, 322, 5866, 29889, 450, 4646, 471, 10423, 411, 274, 2722, 322, 885, 1633, 29879, 408, 278, 323, 8929, 293, 14205, 269, 804, 964, 278, 3889, 19583, 19922, 310, 278, 4644, 19948, 29889, 13, 13, 797, 278, 1095, 29892, 871, 263, 2846, 6893, 10503, 440, 943, 892, 620, 4979, 287, 491, 278, 390, 4345, 1704, 2084, 423, 29892, 607, 11977, 373, 278, 9088, 3196, 6199, 2678, 29889, 450, 323, 8929, 293, 766, 1901, 471, 697, 310, 278, 7123, 20409, 1766, 21998, 1035, 16719, 297, 4955, 29892, 322, 372, 723, 22296, 1735, 278, 982, 13968, 892, 8688, 322, 19623, 29889, 19454, 278, 1020, 3192, 29891, 29892, 278, 15983, 310, 278, 323, 8929, 293, 10600, 373, 29892, 263, 1083, 4995, 310, 278, 3081, 310, 5469, 322, 278, 5227, 24208, 310, 5199, 19981, 17118, 29889])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52a50b-52b9-4956-8c4a-62c2d6d01444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33f7808b-c7b8-40c6-ad3e-08affcfe4b07",
   "metadata": {},
   "source": [
    "###  Creating a chat between the user and the model with ollama chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d7ced5-e591-4896-8367-a2d0bc3573cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llamea2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "061d511d-640d-4418-80db-ae7ac28b19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of Chat History\n",
    "\n",
    "chat_history = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"You are creative writer that writes short stories in any given genre and generates 5 title for the story.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\"content\": \"Generate a short story not more than 150 words about titanic.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d23e2a5-095d-412c-a09c-b88d6dc667e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_chat = ollama.chat(model=model,\n",
    "                        messages =chat_history)\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b6b91c8-435e-442e-84c4-6498dcf9806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ollama._types.ChatResponse"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1203c3ae-81d3-4419-a20a-d9d0e1f084da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are five possible titles for a short story about the Titanic:\n",
      "\n",
      "1. \"The Fateful Night\"\n",
      "2. \"Titanic's Final Hour\"\n",
      "3. \"The Ship of Dreams Sinks\"\n",
      "4. \"The Tragic End of an Era\"\n",
      "5. \"The Iceberg that Changed History\"\n",
      "\n",
      "Here is a short story not more than 150 words based on one of these titles:\n",
      "\n",
      "Title: \"The Fateful Night\"\n",
      "\n",
      "As the Titanic sailed through the frigid waters of the North Atlantic, passengers and crew alike felt a sense of unease. Little did they know that fate had already taken hold of their lives, and that the ship would soon be plunging to its doom. On that fateful night, as the Titanic struck the iceberg, the world changed forever. The ship's tragic end marked the beginning of a new era in maritime history, one that would never forget the lessons of the Titanic's fate.\n"
     ]
    }
   ],
   "source": [
    "print(result_chat[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002647c5-9b03-4382-a56f-8c1979c44809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167949cb-e8e7-4167-94f4-e53184af848c",
   "metadata": {},
   "source": [
    "### Creating a function for chat history and an interactive chart with ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "943335ec-e4b2-451d-b79b-5dfbe0f51d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can start chatting with Llama2. (Type 'exit' to stop)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Model: \n",
       "In the depths of the ocean, where the light barely reaches, a group of mermaids stumbled upon the wreckage of the Titanic. They had heard stories of the doomed ship, but never imagined they would find it in such a state. As they swam through the corridors, they saw the remnants of the lives that were lost, the splendor now nothing more than rust and decay. One mermaid, intrigued by the human artifacts, picked up a small piece of wood and examined it closely. Suddenly, she heard a faint whisper, a message from beyond the grave. The mermaids listened in awe as the voice of a young woman echoed through the wreckage, telling the tale of love and loss on that fateful night."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  give a title\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Model: \n",
       "As the Titanic sank into the icy waters of the North Atlantic, its passengers and crew fought for their lives. The ship's band played on, their music a haunting reminder of the tragedy unfolding before them. Amidst the chaos, a young couple clung to each other, their love stronger than the sea that threatened to tear them apart. In the end, only a few hundred survived the night, their stories etched into history forever.\n",
       "\n",
       "Here are five possible titles for this short story:\n",
       "\n",
       "1. \"The Last Dance on the Titanic\"\n",
       "2. \"Love in the Face of Death\"\n",
       "3. \"Tragedy at Sea\"\n",
       "4. \"The Sinking of the Titanic\"\n",
       "5. \"Surviving the Nightmare\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def ollama_chat_history(messages):\n",
    "    model = \"llama2\"\n",
    "    messages = [\n",
    "        {\n",
    "        \"role\": \"system\", \"content\": \"You are creative writer that writes short stories in any given genre and generates 5 title for the story.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\"content\": \"Generate a short story not more than 150 words about titanic.\"\n",
    "    }\n",
    "    ]\n",
    "    response = ollama.chat(model=model, messages=messages)\n",
    "    messages.append({\"role\": \"system\", \"content\": response[\"message\"][\"content\"]})\n",
    "    return response[\"message\"][\"content\"], messages\n",
    "\n",
    "\n",
    "def interactive_chat():\n",
    "    print(\"You can start chatting with Llama2. (Type 'exit' to stop)\")\n",
    "    messages = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        response, messages = ollama_chat_history(messages)\n",
    "\n",
    "        display(Markdown(f\"Model: {response}\"))\n",
    "\n",
    "\n",
    "interactive_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f94f85-860b-4f68-ba7d-c1162f16c972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab734fd-f968-4676-9069-7f0ee8dc0468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b387bbef-909e-4adf-9e35-d0f97462a34a",
   "metadata": {},
   "source": [
    "### Story Creator function -- introducig genre,themes,style and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc88e9c3-54bd-489a-9926-27e3191d1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Length = [100, 250, 750]\n",
    "Length = [l for l in Length if l >= 100]\n",
    "r_length = random.choice(Length)\n",
    "\n",
    "Genre = [\"Fiction\", \"Nonfiction\", \"Drama\", \"Poetry\", \"Fantasy\", \"Horror\", \"Mystery\", \"Science Fiction\", \"Suspense\", \"Women's fiction\", \"Supernatural/Paranormal\", \"Suspense\", \"Young adult\"]\n",
    "r_genre= random.choice(Genre)\n",
    "\n",
    "Themes = [\"Love\", \"Redemption\", \"Forgiveness\", \"Coming of age\", \"Revenge\", \"Good vs evil\", \"Bravery and hardship\", \"The power of social status\",\"The destructive nature of love\", \"The fallibility of the human condition\"]\n",
    "r_themes= random.choice(Themes)\n",
    "\n",
    "Writing_Styles = [\"Expository\", \"Narrative\", \"Descriptive\", \"Persuasive\", \"creative\"]\n",
    "r_Style= random.choice(Writing_Styles)\n",
    "\n",
    "Tones = [\"Formal\", \"Formal\", \"Optimistic\", \"Worried\", \"Friendly\", \"Curious\", \"Assertive\", \"Encouraging\"]\n",
    "r_tones= random.choice(Tones)\n",
    "\n",
    "\n",
    "\n",
    "def chat_short_story(length, genre, theme, tone, writing_style):\n",
    "    system_message = \"You are a highly creative short story writer capable of writing across any genre and generate a  title for a story\"\n",
    "    \n",
    "    prompt = (f\"Write a creative short story of {100} words in the {r_genre} genre. \"\n",
    "          f\"Use a {r_Style} writing style with a {r_tones} tone. \"\n",
    "          f\"The story should revolve around the theme of {r_themes}. Include a conflict that drives the plot, \"\n",
    "          f\"and create a compelling narrative to captivate the audience.\")\n",
    "\n",
    "\n",
    "    result = ollama.chat(model=\"llama2\",  messages= [\n",
    "    {\n",
    "        \"role\": \"assistant\", \"content\": system_message,\n",
    "        \"role\": \"user\", \"content\": prompt,\n",
    "    },\n",
    "])\n",
    "\n",
    "    story = \"\"\n",
    "\n",
    "    if isinstance(result, list):\n",
    "        for para in result:\n",
    "            story += para\n",
    "    else:\n",
    "        story = result[\"message\"][\"content\"]\n",
    "    \n",
    "    return story\n",
    "\n",
    "story = chat_short_story(100, \"Suspense\", \"Love\", \"Curious\",\"Creative\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88c9be88-58a4-4a27-828f-b3a53b0741fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Title: A Path to Forgiveness\n",
       "\n",
       "As I walked through the forest, the crunch of leaves beneath my feet echoed my inner struggle. My heart heavy with the weight of resentment, I couldn't shake off the bitterness that had been consuming me for so long. But then, a gentle breeze rustled the trees, and a soft voice whispered in my ear: \"Forgiveness is the path to healing.\"\n",
       "\n",
       "I stopped dead in my tracks, my breath catching in my throat. The voice, so gentle yet firm, seemed to come from within me. It was as if the forest itself was guiding me towards a profound realization: forgiveness wasn't just a virtue, but a powerful tool for healing and growth.\n",
       "\n",
       "With newfound determination, I took a deep breath and began my journey down this path of forgiveness. The trees seemed to part ways as I walked, their branches reaching out to embrace me in a warm, comforting embrace. And as I left the forest, I felt lighter, freer â€“ no longer burdened by the weight of resentment, but empowered by the strength of forgiveness."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd64e4c-45b9-4f9b-927f-d82c4c67681b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fecfb-6404-4eee-be8b-a10d1a69d649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d8d6c0-f69d-46ce-9a6d-72c02926e6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bac34-edcb-49ca-9a7c-da1d1be62210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aede76-672e-45af-a524-fba77915afca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2beebf3a-64d6-4d51-b211-dcbd42572553",
   "metadata": {},
   "source": [
    "## Integrating my Story Creator function to an interactive chat session with llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d76168-1304-40ad-bcbb-60d56480aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can start chatting with the short story generator. (Type 'exit' to stop)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Generated Story:**\n",
       "\n",
       "\n",
       "\"The Gilded Cage\"\n",
       "\n",
       "In the grand estate of the wealthy and powerful, resided a horror unlike any other. The screams of the enslaved echoed through the halls, as they toiled away in service to their oppressors. But when a young woman from a lowly background stumbled upon the estate, she discovered a secret that would change everything. For within its gilded walls, lay a dark and twisted power, one that had been hidden for centuries. As she delved deeper into the mystery, she found herself trapped in a web of fear and obsession, forced to confront the true horror of the estate's dark past. And as she fought for escape, she realized that the only way out was through the very power that had enslaved them all."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  give another title for this same story\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Generated Story:**\n",
       "\n",
       "\n",
       "Title: The Social Climber's Downfall\n",
       "\n",
       "As she ascended the grand staircase, her heels clicking on the marble steps, Emily couldn't help but feel a sense of satisfaction with her newfound social status. She had finally made it to the elite circle, the one that held parties in mansions and vacationed in exclusive islands. But little did she know, there was a price to pay for such elevated standing.\n",
       "\n",
       "At night, when the lights were dimmed and the guests were settled in their beds, the house would transform into a living hell. The walls whispered secrets of those who had climbed too high, and the shadows seemed to come alive with malevolent intentions. And Emily, the social climber, was about to find out just how deadly the power of status could be."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from IPython.display import display, Markdown\n",
    "import ollama  # Assuming you have the correct library installed\n",
    "\n",
    "# Define possible options\n",
    "Length = [100, 250, 750]\n",
    "Length = [l for l in Length if l >= 100]\n",
    "r_length = random.choice(Length)\n",
    "\n",
    "Genre = [\n",
    "    \"Fiction\", \"Nonfiction\", \"Drama\", \"Poetry\", \"Fantasy\", \"Horror\", \"Mystery\",\n",
    "    \"Science Fiction\", \"Suspense\", \"Women's fiction\", \"Supernatural/Paranormal\", \"Young adult\"\n",
    "]\n",
    "r_genre = random.choice(Genre)\n",
    "\n",
    "Themes = [\n",
    "    \"Love\", \"Redemption\", \"Forgiveness\", \"Coming of age\", \"Revenge\", \"Good vs evil\",\n",
    "    \"Bravery and hardship\", \"The power of social status\", \"The destructive nature of love\",\n",
    "    \"The fallibility of the human condition\"\n",
    "]\n",
    "r_themes = random.choice(Themes)\n",
    "\n",
    "Writing_Styles = [\"Expository\", \"Narrative\", \"Descriptive\", \"Persuasive\", \"Creative\"]\n",
    "r_Style = random.choice(Writing_Styles)\n",
    "\n",
    "Tones = [\"Formal\", \"Optimistic\", \"Worried\", \"Friendly\", \"Curious\", \"Assertive\", \"Encouraging\"]\n",
    "r_tones = random.choice(Tones)\n",
    "\n",
    "\n",
    "def chat_short_story(length, genre, theme, tone, writing_style):\n",
    "    # Set the system message for the assistant\n",
    "    system_message = \"You are a highly creative short story writer capable of writing across any genre and generating a title for a story.\"\n",
    "    \n",
    "    # Construct the prompt with all the details\n",
    "    prompt = (\n",
    "        f\"Write a creative short story of {length} words in the {genre} genre. \"\n",
    "        f\"Use a {writing_style} writing style with a {tone} tone. \"\n",
    "        f\"The story should revolve around the theme of {theme}. \"\n",
    "        f\"and create a compelling narrative to captivate the audience.\"\n",
    "    )\n",
    "\n",
    "    # Interact with the model using ollama.chat\n",
    "    result = ollama.chat(\n",
    "        model=\"llama2\",  # Replace with the correct model identifier you want to use\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Assuming the result contains a key \"content\" for the story output\n",
    "    return result[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def interactive_chat():\n",
    "    print(\"You can start chatting with the short story generator. (Type 'exit' to stop)\")\n",
    "    messages = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Generate a response using the model\n",
    "        response = chat_short_story(100, r_genre, r_themes, r_tones, r_Style)\n",
    "\n",
    "        # Display the response (the short story)\n",
    "        display(Markdown(f\"**Generated Story:**\\n\\n{response}\"))\n",
    "\n",
    "# Run the interactive chat\n",
    "interactive_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdd783c-d195-4f72-94d8-5ab51059da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ------------------\n",
      "aiobotocore                       2.12.3\n",
      "aiofiles                          23.2.1\n",
      "aiohappyeyeballs                  2.4.0\n",
      "aiohttp                           3.10.5\n",
      "aioitertools                      0.7.1\n",
      "aiosignal                         1.2.0\n",
      "alabaster                         0.7.16\n",
      "altair                            5.0.1\n",
      "anaconda-anon-usage               0.4.4\n",
      "anaconda-catalogs                 0.2.0\n",
      "anaconda-client                   1.12.3\n",
      "anaconda-cloud-auth               0.5.1\n",
      "anaconda-navigator                2.6.3\n",
      "anaconda-project                  0.11.1\n",
      "annotated-types                   0.6.0\n",
      "anyio                             4.2.0\n",
      "appdirs                           1.4.4\n",
      "applaunchservices                 0.3.0\n",
      "appnope                           0.1.3\n",
      "appscript                         1.2.5\n",
      "archspec                          0.2.3\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "arrow                             1.2.3\n",
      "astroid                           2.14.2\n",
      "astropy                           6.1.3\n",
      "astropy-iers-data                 0.2024.9.2.0.33.23\n",
      "asttokens                         2.0.5\n",
      "async-lru                         2.0.4\n",
      "atomicwrites                      1.4.0\n",
      "attrs                             23.1.0\n",
      "Automat                           20.2.0\n",
      "autopep8                          2.0.4\n",
      "Babel                             2.11.0\n",
      "bcrypt                            3.2.0\n",
      "beautifulsoup4                    4.12.3\n",
      "binaryornot                       0.4.4\n",
      "black                             24.8.0\n",
      "bleach                            4.1.0\n",
      "blinker                           1.6.2\n",
      "bokeh                             3.6.0\n",
      "boltons                           23.0.0\n",
      "botocore                          1.34.69\n",
      "Bottleneck                        1.3.7\n",
      "Brotli                            1.0.9\n",
      "cachetools                        5.3.3\n",
      "certifi                           2024.8.30\n",
      "cffi                              1.17.1\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                3.3.2\n",
      "click                             8.1.7\n",
      "cloudpickle                       3.0.0\n",
      "colorama                          0.4.6\n",
      "colorcet                          3.1.0\n",
      "comm                              0.2.1\n",
      "conda                             24.9.2\n",
      "conda-build                       24.9.0\n",
      "conda-content-trust               0.2.0\n",
      "conda_index                       0.5.0\n",
      "conda-libmamba-solver             24.9.0\n",
      "conda-pack                        0.7.1\n",
      "conda-package-handling            2.3.0\n",
      "conda_package_streaming           0.10.0\n",
      "conda-repo-cli                    1.0.114\n",
      "conda-token                       0.5.0+1.g2209e04\n",
      "constantly                        23.10.4\n",
      "contourpy                         1.2.0\n",
      "cookiecutter                      2.6.0\n",
      "cryptography                      43.0.0\n",
      "cssselect                         1.2.0\n",
      "cycler                            0.11.0\n",
      "cytoolz                           0.12.2\n",
      "dask                              2024.8.2\n",
      "dask-expr                         1.1.13\n",
      "datashader                        0.16.3\n",
      "debugpy                           1.6.7\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "diff-match-patch                  20200713\n",
      "dill                              0.3.8\n",
      "distributed                       2024.8.2\n",
      "distro                            1.9.0\n",
      "dmglib                            0.9.5\n",
      "docstring_parser                  0.16\n",
      "docstring-to-markdown             0.11\n",
      "docutils                          0.18.1\n",
      "et-xmlfile                        1.1.0\n",
      "executing                         0.8.3\n",
      "fastapi                           0.115.6\n",
      "fastjsonschema                    2.16.2\n",
      "ffmpy                             0.5.0\n",
      "filelock                          3.13.1\n",
      "flake8                            7.0.0\n",
      "Flask                             3.0.3\n",
      "fonttools                         4.51.0\n",
      "frozendict                        2.4.2\n",
      "frozenlist                        1.4.0\n",
      "fsspec                            2024.6.1\n",
      "gensim                            4.3.3\n",
      "gitdb                             4.0.7\n",
      "GitPython                         3.1.43\n",
      "google-ai-generativelanguage      0.6.10\n",
      "google-api-core                   2.24.0\n",
      "google-api-python-client          2.156.0\n",
      "google-auth                       2.37.0\n",
      "google-auth-httplib2              0.2.0\n",
      "google-cloud-aiplatform           1.75.0\n",
      "google-cloud-bigquery             3.27.0\n",
      "google-cloud-core                 2.4.1\n",
      "google-cloud-resource-manager     1.14.0\n",
      "google-cloud-storage              2.19.0\n",
      "google-crc32c                     1.6.0\n",
      "google-generativeai               0.8.3\n",
      "google-resumable-media            2.7.2\n",
      "googleapis-common-protos          1.66.0\n",
      "gradio                            5.9.1\n",
      "gradio_client                     1.5.2\n",
      "greenlet                          3.0.1\n",
      "grpc-google-iam-v1                0.13.1\n",
      "grpcio                            1.68.1\n",
      "grpcio-status                     1.68.1\n",
      "h11                               0.14.0\n",
      "h5py                              3.11.0\n",
      "HeapDict                          1.0.1\n",
      "holoviews                         1.19.1\n",
      "httpcore                          1.0.2\n",
      "httplib2                          0.22.0\n",
      "httpx                             0.27.0\n",
      "huggingface-hub                   0.27.1\n",
      "hvplot                            0.11.0\n",
      "hyperlink                         21.0.0\n",
      "idna                              3.7\n",
      "imagecodecs                       2023.1.23\n",
      "imageio                           2.33.1\n",
      "imagesize                         1.4.1\n",
      "imbalanced-learn                  0.12.3\n",
      "importlib-metadata                7.0.1\n",
      "incremental                       22.10.0\n",
      "inflection                        0.5.1\n",
      "iniconfig                         1.1.1\n",
      "intake                            2.0.7\n",
      "intervaltree                      3.1.0\n",
      "ipykernel                         6.28.0\n",
      "ipython                           8.27.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        7.8.1\n",
      "isort                             5.13.2\n",
      "itemadapter                       0.3.0\n",
      "itemloaders                       1.1.0\n",
      "itsdangerous                      2.2.0\n",
      "jaraco.classes                    3.2.1\n",
      "jedi                              0.19.1\n",
      "jellyfish                         1.0.1\n",
      "Jinja2                            3.1.4\n",
      "jiter                             0.8.2\n",
      "jmespath                          1.0.1\n",
      "joblib                            1.4.2\n",
      "json5                             0.9.6\n",
      "jsonpatch                         1.33\n",
      "jsonpointer                       2.1\n",
      "jsonschema                        4.23.0\n",
      "jsonschema-specifications         2023.7.1\n",
      "jupyter                           1.0.0\n",
      "jupyter_client                    8.6.0\n",
      "jupyter-console                   6.6.3\n",
      "jupyter_core                      5.7.2\n",
      "jupyter-events                    0.10.0\n",
      "jupyter-lsp                       2.2.0\n",
      "jupyter_server                    2.14.1\n",
      "jupyter_server_terminals          0.4.4\n",
      "jupyterlab                        4.2.5\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab_server                 2.27.3\n",
      "jupyterlab-widgets                1.0.0\n",
      "keyring                           24.3.1\n",
      "kiwisolver                        1.4.4\n",
      "lazy_loader                       0.4\n",
      "lazy-object-proxy                 1.10.0\n",
      "lckr_jupyterlab_variableinspector 3.1.0\n",
      "libarchive-c                      5.1\n",
      "libmambapy                        1.5.8\n",
      "linkify-it-py                     2.0.0\n",
      "llvmlite                          0.43.0\n",
      "lmdb                              1.4.1\n",
      "locket                            1.0.0\n",
      "lxml                              5.2.1\n",
      "lz4                               4.3.2\n",
      "Markdown                          3.4.1\n",
      "markdown-it-py                    2.2.0\n",
      "MarkupSafe                        2.1.3\n",
      "matplotlib                        3.9.2\n",
      "matplotlib-inline                 0.1.6\n",
      "mccabe                            0.7.0\n",
      "mdit-py-plugins                   0.3.0\n",
      "mdurl                             0.1.0\n",
      "menuinst                          2.1.2\n",
      "mistune                           2.0.4\n",
      "more-itertools                    10.3.0\n",
      "mpmath                            1.3.0\n",
      "msgpack                           1.0.3\n",
      "multidict                         6.0.4\n",
      "multipledispatch                  0.6.0\n",
      "mypy                              1.11.2\n",
      "mypy-extensions                   1.0.0\n",
      "navigator-updater                 0.5.1\n",
      "nbclient                          0.8.0\n",
      "nbconvert                         7.16.4\n",
      "nbformat                          5.10.4\n",
      "nest-asyncio                      1.6.0\n",
      "networkx                          3.3\n",
      "nltk                              3.9.1\n",
      "notebook                          7.2.2\n",
      "notebook_shim                     0.2.3\n",
      "numba                             0.60.0\n",
      "numexpr                           2.8.7\n",
      "numpy                             1.26.4\n",
      "numpydoc                          1.7.0\n",
      "ollama                            0.4.5\n",
      "openai                            1.58.1\n",
      "openpyxl                          3.1.5\n",
      "orjson                            3.10.13\n",
      "overrides                         7.4.0\n",
      "packaging                         24.1\n",
      "pandas                            2.2.2\n",
      "pandocfilters                     1.5.0\n",
      "panel                             1.5.2\n",
      "param                             2.1.1\n",
      "parsel                            1.8.1\n",
      "parso                             0.8.3\n",
      "partd                             1.4.1\n",
      "pathspec                          0.10.3\n",
      "patsy                             0.5.6\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "pillow                            10.4.0\n",
      "pip                               24.2\n",
      "pkce                              1.0.3\n",
      "pkginfo                           1.10.0\n",
      "platformdirs                      3.10.0\n",
      "plotly                            5.24.1\n",
      "pluggy                            1.0.0\n",
      "ply                               3.11\n",
      "prometheus-client                 0.14.1\n",
      "prompt-toolkit                    3.0.43\n",
      "Protego                           0.1.16\n",
      "proto-plus                        1.25.0\n",
      "protobuf                          5.29.2\n",
      "psutil                            5.9.0\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "py-cpuinfo                        9.0.0\n",
      "pyarrow                           16.1.0\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.8\n",
      "pycodestyle                       2.11.1\n",
      "pycosat                           0.6.6\n",
      "pycparser                         2.21\n",
      "pyct                              0.5.0\n",
      "pycurl                            7.45.3\n",
      "pydantic                          2.10.4\n",
      "pydantic_core                     2.27.2\n",
      "pydeck                            0.8.0\n",
      "PyDispatcher                      2.0.5\n",
      "pydocstyle                        6.3.0\n",
      "pydub                             0.25.1\n",
      "pyerfa                            2.0.1.4\n",
      "pyflakes                          3.2.0\n",
      "Pygments                          2.15.1\n",
      "PyJWT                             2.8.0\n",
      "pylint                            2.16.2\n",
      "pylint-venv                       3.0.3\n",
      "pyls-spyder                       0.4.0\n",
      "pyobjc-core                       10.1\n",
      "pyobjc-framework-Cocoa            10.1\n",
      "pyobjc-framework-CoreServices     10.1\n",
      "pyobjc-framework-FSEvents         10.1\n",
      "pyodbc                            5.1.0\n",
      "pyOpenSSL                         24.2.1\n",
      "pyparsing                         3.1.2\n",
      "PyPDF2                            3.0.1\n",
      "PyQt5                             5.15.10\n",
      "PyQt5-sip                         12.13.0\n",
      "PyQtWebEngine                     5.15.6\n",
      "PySocks                           1.7.1\n",
      "pytesseract                       0.3.13\n",
      "pytest                            7.4.4\n",
      "python-dateutil                   2.9.0.post0\n",
      "python-dotenv                     0.21.0\n",
      "python-json-logger                2.0.7\n",
      "python-lsp-black                  2.0.0\n",
      "python-lsp-jsonrpc                1.1.2\n",
      "python-lsp-server                 1.10.0\n",
      "python-multipart                  0.0.20\n",
      "python-slugify                    5.0.2\n",
      "pytoolconfig                      1.2.6\n",
      "pytz                              2024.1\n",
      "pyviz_comms                       3.0.2\n",
      "PyWavelets                        1.7.0\n",
      "PyYAML                            6.0.1\n",
      "pyzmq                             25.1.2\n",
      "QDarkStyle                        3.2.3\n",
      "qstylizer                         0.2.2\n",
      "QtAwesome                         1.3.1\n",
      "qtconsole                         5.5.1\n",
      "QtPy                              2.4.1\n",
      "queuelib                          1.6.2\n",
      "referencing                       0.30.2\n",
      "regex                             2024.9.11\n",
      "requests                          2.32.3\n",
      "requests-file                     1.5.1\n",
      "requests-toolbelt                 1.0.0\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rich                              13.7.1\n",
      "rope                              1.12.0\n",
      "rpds-py                           0.10.6\n",
      "rsa                               4.9\n",
      "Rtree                             1.0.1\n",
      "ruamel.yaml                       0.18.6\n",
      "ruamel.yaml.clib                  0.2.8\n",
      "ruamel-yaml-conda                 0.17.21\n",
      "ruff                              0.8.6\n",
      "s3fs                              2024.6.1\n",
      "safehttpx                         0.1.6\n",
      "scikit-image                      0.24.0\n",
      "scikit-learn                      1.5.1\n",
      "scipy                             1.13.1\n",
      "Scrapy                            2.11.1\n",
      "seaborn                           0.13.2\n",
      "semantic-version                  2.10.0\n",
      "semver                            3.0.2\n",
      "Send2Trash                        1.8.2\n",
      "service-identity                  18.1.0\n",
      "setuptools                        75.1.0\n",
      "shapely                           2.0.6\n",
      "shellingham                       1.5.4\n",
      "sip                               6.7.12\n",
      "six                               1.16.0\n",
      "smart-open                        5.2.1\n",
      "smmap                             4.0.0\n",
      "sniffio                           1.3.0\n",
      "snowballstemmer                   2.2.0\n",
      "sortedcontainers                  2.4.0\n",
      "soupsieve                         2.5\n",
      "Sphinx                            7.3.7\n",
      "sphinxcontrib-applehelp           1.0.2\n",
      "sphinxcontrib-devhelp             1.0.2\n",
      "sphinxcontrib-htmlhelp            2.0.0\n",
      "sphinxcontrib-jsmath              1.0.1\n",
      "sphinxcontrib-qthelp              1.0.3\n",
      "sphinxcontrib-serializinghtml     1.1.10\n",
      "spyder                            5.5.1\n",
      "spyder-kernels                    2.5.0\n",
      "SQLAlchemy                        2.0.34\n",
      "stack-data                        0.2.0\n",
      "starlette                         0.41.3\n",
      "statsmodels                       0.14.2\n",
      "streamlit                         1.37.1\n",
      "sympy                             1.13.2\n",
      "tables                            3.10.1\n",
      "tabulate                          0.9.0\n",
      "tblib                             1.7.0\n",
      "tenacity                          8.2.3\n",
      "terminado                         0.17.1\n",
      "text-unidecode                    1.3\n",
      "textdistance                      4.2.1\n",
      "threadpoolctl                     3.5.0\n",
      "three-merge                       0.1.1\n",
      "tifffile                          2023.4.12\n",
      "tinycss2                          1.2.1\n",
      "tldextract                        5.1.2\n",
      "toml                              0.10.2\n",
      "tomli                             2.0.1\n",
      "tomlkit                           0.13.2\n",
      "toolz                             0.12.0\n",
      "tornado                           6.4.1\n",
      "tqdm                              4.66.5\n",
      "traitlets                         5.14.3\n",
      "truststore                        0.8.0\n",
      "Twisted                           23.10.0\n",
      "typer                             0.15.1\n",
      "typing_extensions                 4.12.2\n",
      "tzdata                            2023.3\n",
      "uc-micro-py                       1.0.1\n",
      "ujson                             5.10.0\n",
      "unicodedata2                      15.1.0\n",
      "Unidecode                         1.3.8\n",
      "uritemplate                       4.1.1\n",
      "urllib3                           2.2.3\n",
      "uvicorn                           0.34.0\n",
      "w3lib                             2.1.2\n",
      "watchdog                          4.0.1\n",
      "wcwidth                           0.2.5\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  1.8.0\n",
      "websockets                        14.1\n",
      "Werkzeug                          3.0.3\n",
      "whatthepatch                      1.0.2\n",
      "wheel                             0.44.0\n",
      "widgetsnbextension                3.6.6\n",
      "wrapt                             1.14.1\n",
      "wurlitzer                         3.0.2\n",
      "xarray                            2023.6.0\n",
      "xlrd                              2.0.1\n",
      "xlwings                           0.32.1\n",
      "xyzservices                       2022.9.0\n",
      "yapf                              0.40.2\n",
      "yarl                              1.11.0\n",
      "zict                              3.0.0\n",
      "zipp                              3.17.0\n",
      "zope.interface                    5.4.0\n",
      "zstandard                         0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18c94e-800c-45fe-b5be-234b250c9c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb3909c-2caa-4553-9fac-65925fd197fe",
   "metadata": {},
   "source": [
    "# Building Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ebb4b63-dc2f-4dbf-8c2c-3efe560abb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a11eaa-0be6-4358-bdeb-f78026d8585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "514b6b8f-22ae-4367-ab05-233f12782849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Length = [100, 250, 750]\n",
    "Length = [l for l in Length if l >= 100]\n",
    "r_length = random.choice(Length)\n",
    "\n",
    "Genre = [\n",
    "    \"Fiction\", \"Nonfiction\", \"Drama\", \"Poetry\", \"Fantasy\", \"Horror\", \"Mystery\",\n",
    "    \"Science Fiction\", \"Suspense\", \"Women's fiction\", \"Supernatural/Paranormal\", \"Young adult\"\n",
    "]\n",
    "r_genre = random.choice(Genre)\n",
    "\n",
    "Themes = [\n",
    "    \"Love\", \"Redemption\", \"Forgiveness\", \"Coming of age\", \"Revenge\", \"Good vs evil\",\n",
    "    \"Bravery and hardship\", \"The power of social status\", \"The destructive nature of love\",\n",
    "    \"The fallibility of the human condition\"\n",
    "]\n",
    "r_themes = random.choice(Themes)\n",
    "\n",
    "Writing_Styles = [\"Expository\", \"Narrative\", \"Descriptive\", \"Persuasive\", \"Creative\"]\n",
    "r_Style = random.choice(Writing_Styles)\n",
    "\n",
    "Tones = [\"Formal\", \"Optimistic\", \"Worried\", \"Friendly\", \"Curious\", \"Assertive\", \"Encouraging\"]\n",
    "r_tones = random.choice(Tones)\n",
    "\n",
    "\n",
    "iface = gr.Interface(fn=chat_short_story,inputs=[gr.Slider(value = Length, label = \"Story_Length\", minimum=100,maximum=2500),\n",
    "                                                gr.Dropdown(label= \"Story_Genre\", choices =Genre),\n",
    "                                                gr.Dropdown(label= \"Story_Theme\", choices =Themes),\n",
    "                                                gr.Dropdown(label= \"Writing_Styles\", choices =Writing_Styles),\n",
    "                                                gr.Dropdown(label= \"Story_Tone\", choices =Tones)],outputs = gr.Text(),\n",
    "                    title=\"Patrick's Story Creator App\")\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7720f7a4-ef8e-4128-8cd4-20cc7774133b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1310192510.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter nbextension enable --py widgetsnbextension\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdadcd7-9186-48cd-9f82-c7f0009d4393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb1f80b-e0ea-4212-be65-b34c20134498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (0.27.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edeb688-434e-4b02-9142-65e4a8898b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1739e305-c895-4b65-9c6d-019a00738602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bac4da36dd74088a30d3acb80316934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f669c7-b726-4ce1-8da7-7c4a440f55dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08990869-09c6-4e70-87e0-033686709c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
