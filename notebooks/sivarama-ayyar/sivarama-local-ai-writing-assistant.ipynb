{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T14:32:01.347979Z",
     "start_time": "2025-01-10T14:32:01.345069Z"
    }
   },
   "source": [
    "import ollama\n",
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import google.generativeai as genai\n",
    "LLAMA_MODEL = \"llama3.2\"\n",
    "from dotenv import load_dotenv\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Short Story Creator",
   "id": "c65a268b5e67fe05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:26:10.697316Z",
     "start_time": "2024-12-31T17:26:10.694477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "#user prompt args\n",
    "GENRES = [\"Fiction\", \"Nonfiction\", \"Drama\", \"Poetry\", \"Fantasy\", \"Horror\", \"Mystery\", \"Science Fiction\", \"Suspense\", \"Women's fiction\", \"Supernatural/Paranormal\", \"Suspense\", \"Young adult\"]\n",
    "THEMES = [\"Love\", \"Redemption\", \"Forgiveness\", \"Coming of age\", \"Revenge\", \"Good vs evil\", \"Bravery and hardship\", \"The power of social status\",\"The destructive nature of love\", \"The fallibility of the human condition\"]\n",
    "WRITING_STYLES = [\"Expository\", \"Narrative\", \"Descriptive\", \"Persuasive\", \"creative\"]\n",
    "TONES = [\"Formal\", \"Formal\", \"Optimistic\", \"Worried\", \"Friendly\", \"Curious\", \"Assertive\", \"Encouraging\"]"
   ],
   "id": "14349761e0187f2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:26:24.352972Z",
     "start_time": "2024-12-31T17:26:24.350723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_story_user_prompt(genre, theme, style, tone):\n",
    "    user_prompt = f\"You are looking at genre: {genre}\\n\"\n",
    "    user_prompt += f\"with the theme: {theme}.\\n\"\n",
    "    user_prompt += f\"Author's writingStyle is: {style}.\\n\"\n",
    "    user_prompt += f\"Tone of the story is: {tone}.\"\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ],
   "id": "979e8702df866f2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:27:06.997907Z",
     "start_time": "2024-12-31T17:27:06.994993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_short_story(genre, theme, style, tone):\n",
    "    response = ollama.chat(model=LLAMA_MODEL, messages=[\n",
    "            {\"role\": \"system\", \"content\": story_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_story_user_prompt(genre, theme, style, tone)}\n",
    "          ])\n",
    "    return response['message']['content']"
   ],
   "id": "9faf9ae833aee8df",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:26:51.718074Z",
     "start_time": "2024-12-31T17:26:51.715929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "story_system_prompt = \"You are an creative story writing assistant that takes input like genre, theme, or character type \\\n",
    "and generates a short story.\""
   ],
   "id": "fd4c8dc82ac10717",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:27:30.494618Z",
     "start_time": "2024-12-31T17:27:11.699236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = create_short_story(\"Fiction\", \"Bravery and hardship\", \"Creativity\", \"Encouraging\")\n",
    "print(response)"
   ],
   "id": "b906b7b1a37e1315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Ember of Resilience**\n",
      "\n",
      "In the scorching desert, where dunes stretched like golden seas and sunbeams scorched the earth, a young nomad named Aisha traversed the unforgiving terrain. Her eyes, like two dark stars, shone bright with determination, for she was on a quest to fulfill an unyielding dream.\n",
      "\n",
      "Aisha's village had been ravaged by a brutal sandstorm that left her family homeless and her heart shattered. The loss of her mother, who had taught her the ancient ways of their people, still lingered like an open wound. Yet, Aisha refused to let despair consume her. Instead, she channeled her grief into the flame of resilience that burned within.\n",
      "\n",
      "As she walked, the blistering sun beat down upon her, relentless in its ferocity. The wind howled, threatening to snuff out the ember of hope that flickered within her chest. Yet Aisha persevered, fueled by the memories of her mother's words: \"A brave heart is not one that shuns hardship, but one that finds strength in the face of adversity.\"\n",
      "\n",
      "Days turned into weeks, and the landscape shifted from arid desert to a verdant oasis, where palms swayed in the breeze like nature's own cathedral. It was here that Aisha encountered a wise old man, his eyes kindling with warmth as he beheld her determination.\n",
      "\n",
      "\"Why do you walk this unforgiving path, young one?\" he asked, his voice like a gentle brook.\n",
      "\n",
      "Aisha shared her story, and the old man listened intently, nodding his head in understanding. \"Your mother would be proud of you, Aisha,\" he said, his eyes twinkling with empathy. \"You have taken the fragments of your shattered world and forged them into a tapestry of courage.\"\n",
      "\n",
      "As the days passed, Aisha continued on her journey, facing challenges that tested her resolve. She battled raging sandstorms, navigated treacherous mountain passes, and braved the darkness of unknown nights. With each triumph, the ember within her grew brighter, illuminating the path ahead.\n",
      "\n",
      "And when the winds of fate finally parted to reveal a glimmer of hope, Aisha beheld an oasis unlike any she had ever seen. A shimmering pool of water, reflecting the radiant colors of the setting sun, beckoned her closer. In its tranquil depths, she saw a reflection that was hers alone â€“ a soul tempered by hardship, strengthened by bravery.\n",
      "\n",
      "In that moment, Aisha knew that she had become the very embodiment of resilience, an ember that would burn brightly in the hearts of those who followed. For in the face of adversity, it is not the absence of hardship that defines us, but our ability to kindle a flame of courage that illuminates even the darkest of nights.\n",
      "\n",
      "**Epilogue**\n",
      "\n",
      "As Aisha returned to her village, now rebuilt and stronger than ever, she became a beacon of inspiration to all who knew her. Her story was told and retold around campfires, reminding generations to come of the power of bravery in the face of hardship. And when the winds of fate finally subsided, leaving only a whisper of what once was, Aisha's ember continued to burn, inspiring others to forge their own paths, tempered by the fires of resilience.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:27:37.359105Z",
     "start_time": "2024-12-31T17:27:37.186495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gradio UI\n",
    "gr.Interface(fn=create_short_story, inputs=[gr.Dropdown(GENRES, label=\"genre\", info=\"select your story genre\"),\n",
    "                                gr.Dropdown(THEMES, label=\"theme\", info=\"select your story theme\"),\n",
    "                                gr.Dropdown(WRITING_STYLES, label=\"style\", info=\"select writingStyle\"),\n",
    "                                gr.Dropdown(TONES, label=\"tone\", info=\"select the tone\")\n",
    "             ], outputs=\"textarea\").launch()"
   ],
   "id": "2261c20b7f1ca9cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building Chatbot",
   "id": "500e2e16d5a56278"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:37:45.014779Z",
     "start_time": "2024-12-31T17:37:45.012014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "system_message = \"You are an optimistic assistant and will respond to user queries with positivity\"\n"
   ],
   "id": "9e6c5c36932fcb9e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:37:48.233549Z",
     "start_time": "2024-12-31T17:37:48.228659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = ollama.chat(model=LLAMA_MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "         if 'message' in chunk and 'content' in chunk['message']:\n",
    "            chunk_text = chunk['message']['content']\n",
    "            response += chunk_text or \"\"\n",
    "            yield response"
   ],
   "id": "c9fdfb0bc167a4f5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:43:53.409328Z",
     "start_time": "2024-12-31T17:43:53.272919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gradio UI\n",
    "gr.ChatInterface(fn=chat,\n",
    "                 type='messages',\n",
    "                 chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Type Question Here\", container=False, scale=3),\n",
    "    title=\"helpful Assistant\",\n",
    "    description=\"Ask me a question and I will give you an helpful answer\",\n",
    "    theme=\"Glass\",\n",
    "    examples=[\"Will the sky fall today?\", \"were dinosaur existed before?\", \"Advantages of work life balance\", \"Is yes yes and a no a no\"]).launch()"
   ],
   "id": "aa7b3b217e988bdb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sivaram/Developer/SDS/SDS-CP019-local-ai-writing-assistant/.venv/lib/python3.12/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n",
      "/Users/sivaram/Developer/SDS/SDS-CP019-local-ai-writing-assistant/.venv/lib/python3.12/site-packages/gradio/chat_interface.py:222: UserWarning: The type of the gr.Chatbot does not match the type of the gr.ChatInterface.The type of the gr.ChatInterface, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Website Summarizer",
   "id": "ea376d2eaa2ab736"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:58:42.817410Z",
     "start_time": "2025-01-10T13:58:42.814521Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # A class to represent a Webpage\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ],
   "id": "e8f54dce0416797d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T00:25:16.355591Z",
     "start_time": "2025-01-01T00:25:16.348088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define our system prompt\n",
    "system_prompt = \"You are a creative writing assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond with key points.\""
   ],
   "id": "bc61bfc4dcfc0ca0",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T00:30:29.294043Z",
     "start_time": "2025-01-01T00:30:29.285806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short, crisp summary of this website with key points. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ],
   "id": "2e37f352bee4732",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T00:30:32.369941Z",
     "start_time": "2025-01-01T00:30:32.364924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_urls_from_prompt(prompt):\n",
    "    urls=[]\n",
    "    if prompt is not None:\n",
    "        x= prompt.split()\n",
    "        for i in x:\n",
    "            if i.find(\"https:\")==0 or i.find(\"http:\")==0:\n",
    "                urls.append(i)\n",
    "    return urls"
   ],
   "id": "8c185a1ffb9f498a",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T00:30:34.811939Z",
     "start_time": "2025-01-01T00:30:34.806564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarizer_bot(prompt, history):\n",
    "    url = get_urls_from_prompt(prompt)\n",
    "    try:\n",
    "       prompt += user_prompt_for(Website(url[0]))\n",
    "    except:\n",
    "       prompt += \"No URL provided\"\n",
    "\n",
    "    messages = [\n",
    "            {\"role\":\"assistant\", \"content\":system_prompt},\n",
    "            {\"role\":\"user\", \"content\": prompt}\n",
    "        ]\n",
    "    result = ollama.chat(model=LLAMA_MODEL, messages=messages, stream= True)\n",
    "    response = \"\"\n",
    "    for chunk in result:\n",
    "        if 'message' in chunk and 'content' in chunk['message']:\n",
    "            chunk_text = chunk['message']['content']\n",
    "            response += chunk_text or \"\"\n",
    "            yield response\n",
    "\n"
   ],
   "id": "62f206a0b8fbac39",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T00:32:25.347799Z",
     "start_time": "2025-01-01T00:32:25.196704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gr.ChatInterface(\n",
    "    fn=summarizer_bot,\n",
    "    type=\"messages\",\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Type Question Here\", container=False, scale=3),\n",
    "    title=\"Summarizer bot\",\n",
    "    description=\"Give me the link to a website for which you want a summary of the contents of this website.\",\n",
    "    theme=\"Glass\"\n",
    "    ).launch()"
   ],
   "id": "eab80fc2187dffed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sivaram/Developer/SDS/SDS-CP019-local-ai-writing-assistant/.venv/lib/python3.12/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n",
      "/Users/sivaram/Developer/SDS/SDS-CP019-local-ai-writing-assistant/.venv/lib/python3.12/site-packages/gradio/chat_interface.py:222: UserWarning: The type of the gr.Chatbot does not match the type of the gr.ChatInterface.The type of the gr.ChatInterface, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Brochure Generator Multi model\n",
   "id": "7887aab918d775ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:11:32.398808Z",
     "start_time": "2025-01-10T14:11:32.393918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_message = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Do not use any logos. Respond in markdown.\"\n",
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# Check the key\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"No API key was found - please fix!\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n"
   ],
   "id": "f58318eeb3694f99",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:11:35.802024Z",
     "start_time": "2025-01-10T14:11:35.798606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stream_gemini(prompt):\n",
    "    gemini = genai.GenerativeModel(\n",
    "    model_name='gemini-1.5-flash-001',\n",
    "    safety_settings=None,\n",
    "    system_instruction=system_message\n",
    "    )\n",
    "\n",
    "    response = gemini.generate_content(prompt,  safety_settings=[\n",
    "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"}], stream=True)\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in response:\n",
    "        result += chunk.text\n",
    "        yield result"
   ],
   "id": "d9c02d30a1334de2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:32:54.740455Z",
     "start_time": "2025-01-10T14:32:54.737037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stream_llama(prompt):\n",
    "    response = ollama.chat(\n",
    "        model=LLAMA_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in response:\n",
    "         if 'message' in chunk and 'content' in chunk['message']:\n",
    "            chunk_text = chunk['message']['content']\n",
    "            print(chunk_text)\n",
    "            result += chunk_text or \"\"\n",
    "            yield result"
   ],
   "id": "97baf335f7b78190",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:32:10.171054Z",
     "start_time": "2025-01-10T14:32:10.167501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def debug_llama_output(company_name, url, language, response_tone):\n",
    "    prompt = f\"Please generate a {response_tone} company brochure in {language} for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    response = ollama.chat(\n",
    "        model=LLAMA_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ]\n",
    "    )\n",
    "    return response['message']['content']"
   ],
   "id": "dc724b842185f72f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:32:58.907046Z",
     "start_time": "2025-01-10T14:32:58.902862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stream_brochure(company_name, url, model, language, response_tone):\n",
    "    prompt = f\"Please generate a {response_tone} company brochure in {language} for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"Llama\":\n",
    "        result = stream_llama(prompt)\n",
    "    elif model==\"Gemini\":\n",
    "        result = stream_gemini(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result\n",
    "\n"
   ],
   "id": "7f776752d2f4f1a5",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:33:02.122191Z",
     "start_time": "2025-01-10T14:33:02.002097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"Gemini\", \"Llama\"], label=\"Select model\"),\n",
    "        gr.Dropdown([\"English\", \"French\", \"Spanish\", \"German\", \"Hindi\"]),\n",
    "        gr.Dropdown([\"Informational\", \"Promotional\", \"Humorous\", \"Business\"], label=\"Select tone\")],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    title=\"Welcome to vsstech's Brochure Generator\",\n",
    "    description=\"Generates short brochure for company URL in selected language and tone.\"\n",
    ")\n",
    "view.launch()"
   ],
   "id": "65adc6e8cc54d079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:32:29.905922Z",
     "start_time": "2025-01-10T14:32:14.552610Z"
    }
   },
   "cell_type": "code",
   "source": "debug_llama_output(\"huggingface\", \"https://huggingface.co\", \"English\", \"informational\")",
   "id": "b8ac90e4b0a99065",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Hugging Face: Building the Future of AI\\n\\nWelcome to Hugging Face, a collaborative platform for machine learning researchers and practitioners. Our mission is to empower individuals and organizations to build, share, and apply AI models across various domains.\\n\\n## What We Offer\\n\\n* **Models**: Access over 400,000 pre-trained models, including state-of-the-art Transformers, Diffusers, and computer vision models.\\n* **Datasets**: Browse 100,000+ datasets for computer vision, audio, and NLP tasks.\\n* **Spaces**: Run scalable and versatile applications on our platforms, including 3D generation from images and GPU-inference endpoints.\\n* **Compute**: Deploy optimized inference endpoints or update your Spaces applications to a GPU in just a few clicks.\\n\\n## Why Choose Hugging Face?\\n\\n* **Collaboration Platform**: Host and collaborate on unlimited public models, datasets, and applications with our community of researchers and practitioners.\\n* **Open-Source Stack**: Leverage our open-source stack to accelerate your machine learning projects with ease.\\n* **Scalable Solutions**: Access scalable solutions for enterprise-grade security, access controls, and dedicated support.\\n\\n## Benefits for Organizations\\n\\n* **Enterprise-Grade Security**: Protect sensitive data with our robust security features.\\n* **Access Controls**: Easily manage user access with our intuitive interface.\\n* **Dedicated Support**: Get personalized support from our team of experts.\\n\\n## Join the Community\\n\\n* **Sign Up**: Accelerate your machine learning journey by signing up for free today.\\n* **Explore Our Resources**: Dive into our documentation, blog, and forum to learn more about Hugging Face's solutions.\\n\\n### Key Statistics\\n\\n* Over 50,000 organizations trust Hugging Face for their AI needs.\\n* More than 200,000 models are available in our hub.\\n* Our community of researchers and practitioners is growing rapidly, with over 1.87 million followers across our platforms.\\n\\n### Get Started Today!\\n\\nJoin the future of AI today by signing up for free on our website.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6e67fd0d46809c30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
